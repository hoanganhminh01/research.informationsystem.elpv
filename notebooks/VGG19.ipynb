{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.abspath(os.path.dirname(\"__file__\")), '..'))\n",
    "from utils import data_handling, model_development\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Configure the model training policy:\n",
    "#\n",
    "model_development.configure_training_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2624, 300, 300), 2624, 2624]\n",
      "[(2624, 300, 300, 3), 2624, 2624]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b39c5e837646219ca6640bbd04175f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='n', max=2623), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3c160eeddc4d68be5c9e50d773552e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='n', max=2623), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##\n",
    "# Load and preprocess data:\n",
    "#\n",
    "cell_images, cell_labels, cell_types = data_handling.load_data_from_file('../data/labels.csv', True)\n",
    "X, Y, Z = data_handling.preprocess_data(cell_images, cell_labels, cell_types)\n",
    "\n",
    "print([cell_images.shape, len(cell_labels), len(cell_types)])\n",
    "print([X.shape, len(Y), len(Z)])\n",
    "\n",
    "@interact(n = (0, cell_images.shape[0] - 1))\n",
    "def display_data(n = 0):\n",
    "    fig, axs = plt.subplots()\n",
    "    axs.imshow(cell_images[n], cmap = 'gray')\n",
    "    axs.set_title(f'Class: {cell_labels[n]} - Type: {cell_types[n]}')\n",
    "    return None\n",
    "\n",
    "@interact(n = (0, X.shape[0] - 1))\n",
    "def display_data(n = 0):\n",
    "    fig, axs = plt.subplots()\n",
    "    axs.imshow(X[n], cmap = 'gray')\n",
    "    axs.set_title(f'Class: {Y[n]} - Type: {Z[n]}')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Prepare data for model training:\n",
    "#\n",
    "X_train, Y_train, Z_train = X[: 2000], Y[: 2000], Z[: 2000]\n",
    "X_val, Y_val, Z_val = X[2000 : ], Y[2000 : ], Z[2000 : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.8111 - accuracy: 0.5506 - precision: 0.4362 - recall: 0.1541\n",
      "Epoch 1: val_accuracy improved from -inf to 0.56750, saving model to ../models/weights\\VGG19_20221001_fs.hdf5\n",
      "400/400 [==============================] - 29s 62ms/step - loss: 0.8111 - accuracy: 0.5506 - precision: 0.4362 - recall: 0.1541 - val_loss: 0.6845 - val_accuracy: 0.5675 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6752 - accuracy: 0.5813 - precision: 0.5692 - recall: 0.1076\n",
      "Epoch 2: val_accuracy improved from 0.56750 to 0.58000, saving model to ../models/weights\\VGG19_20221001_fs.hdf5\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.6752 - accuracy: 0.5813 - precision: 0.5692 - recall: 0.1076 - val_loss: 0.6772 - val_accuracy: 0.5800 - val_precision: 1.0000 - val_recall: 0.0289\n",
      "Epoch 3/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6695 - accuracy: 0.6000 - precision: 0.5750 - recall: 0.2674\n",
      "Epoch 3: val_accuracy did not improve from 0.58000\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 0.6695 - accuracy: 0.6000 - precision: 0.5750 - recall: 0.2674 - val_loss: 0.6755 - val_accuracy: 0.5700 - val_precision: 1.0000 - val_recall: 0.0058\n",
      "Epoch 4/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6604 - accuracy: 0.6162 - precision: 0.5881 - recall: 0.3590\n",
      "Epoch 4: val_accuracy improved from 0.58000 to 0.59250, saving model to ../models/weights\\VGG19_20221001_fs.hdf5\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 0.6604 - accuracy: 0.6162 - precision: 0.5881 - recall: 0.3590 - val_loss: 0.6755 - val_accuracy: 0.5925 - val_precision: 0.6250 - val_recall: 0.1445\n",
      "Epoch 5/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6583 - accuracy: 0.6112 - precision: 0.5676 - recall: 0.4026\n",
      "Epoch 5: val_accuracy did not improve from 0.59250\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.6583 - accuracy: 0.6112 - precision: 0.5676 - recall: 0.4026 - val_loss: 0.7855 - val_accuracy: 0.4525 - val_precision: 0.4378 - val_recall: 0.9364\n",
      "Epoch 6/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6466 - accuracy: 0.6338 - precision: 0.6483 - recall: 0.3241\n",
      "Epoch 6: val_accuracy did not improve from 0.59250\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.6466 - accuracy: 0.6338 - precision: 0.6483 - recall: 0.3241 - val_loss: 0.9467 - val_accuracy: 0.4625 - val_precision: 0.4441 - val_recall: 0.9653\n",
      "Epoch 7/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6443 - accuracy: 0.6319 - precision: 0.6486 - recall: 0.3140\n",
      "Epoch 7: val_accuracy did not improve from 0.59250\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.6443 - accuracy: 0.6319 - precision: 0.6486 - recall: 0.3140 - val_loss: 0.9485 - val_accuracy: 0.4675 - val_precision: 0.4457 - val_recall: 0.9480\n",
      "Epoch 8/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6341 - accuracy: 0.6506 - precision: 0.6985 - recall: 0.3299\n",
      "Epoch 8: val_accuracy did not improve from 0.59250\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.6341 - accuracy: 0.6506 - precision: 0.6985 - recall: 0.3299 - val_loss: 0.7718 - val_accuracy: 0.4875 - val_precision: 0.4474 - val_recall: 0.7861\n",
      "Epoch 9/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6511 - accuracy: 0.6294 - precision: 0.6877 - recall: 0.2529\n",
      "Epoch 9: val_accuracy did not improve from 0.59250\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.6511 - accuracy: 0.6294 - precision: 0.6877 - recall: 0.2529 - val_loss: 1.1225 - val_accuracy: 0.5175 - val_precision: 0.3148 - val_recall: 0.0983\n",
      "Epoch 10/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6257 - accuracy: 0.6513 - precision: 0.7097 - recall: 0.3198\n",
      "Epoch 10: val_accuracy did not improve from 0.59250\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 0.6257 - accuracy: 0.6513 - precision: 0.7097 - recall: 0.3198 - val_loss: 1.1509 - val_accuracy: 0.4725 - val_precision: 0.3797 - val_recall: 0.3468\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Train classification model (first phase):\n",
    "#\n",
    "vgg19 = \\\n",
    "    model_development.vgg19(input_shape = (300, 300, 3), weights = 'imagenet', finetune_convolution_base = False,display_model_information = False)\n",
    "history, training_time = \\\n",
    "    model_development.train_classification_model(training_phase = 1, \n",
    "    model = vgg19, model_path = '', model_name = 'VGG19', version = '20221001_fs', \n",
    "    X = X_train, Y = Y_train, metric_to_monitor = 'val_accuracy', \n",
    "    no_of_epochs = 200, batch_size = 4, validation_split_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6471 - accuracy: 0.6356 - precision: 0.6400 - recall: 0.3488\n",
      "Epoch 1: val_accuracy improved from -inf to 0.46500, saving model to ../models/weights\\VGG19_20221001_ss.hdf5\n",
      "400/400 [==============================] - 30s 69ms/step - loss: 0.6471 - accuracy: 0.6356 - precision: 0.6400 - recall: 0.3488 - val_loss: 0.8007 - val_accuracy: 0.4650 - val_precision: 0.4456 - val_recall: 0.9711\n",
      "Epoch 2/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.6431 - precision: 0.6834 - recall: 0.3169\n",
      "Epoch 2: val_accuracy improved from 0.46500 to 0.66250, saving model to ../models/weights\\VGG19_20221001_ss.hdf5\n",
      "400/400 [==============================] - 27s 69ms/step - loss: 0.6358 - accuracy: 0.6431 - precision: 0.6834 - recall: 0.3169 - val_loss: 0.6417 - val_accuracy: 0.6625 - val_precision: 0.6092 - val_recall: 0.6127\n",
      "Epoch 3/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6368 - accuracy: 0.6500 - precision: 0.6768 - recall: 0.3561\n",
      "Epoch 3: val_accuracy did not improve from 0.66250\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.6368 - accuracy: 0.6500 - precision: 0.6768 - recall: 0.3561 - val_loss: 0.7804 - val_accuracy: 0.5900 - val_precision: 1.0000 - val_recall: 0.0520\n",
      "Epoch 4/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6321 - accuracy: 0.6425 - precision: 0.6758 - recall: 0.3241\n",
      "Epoch 4: val_accuracy did not improve from 0.66250\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.6321 - accuracy: 0.6425 - precision: 0.6758 - recall: 0.3241 - val_loss: 0.8417 - val_accuracy: 0.4650 - val_precision: 0.4444 - val_recall: 0.9480\n",
      "Epoch 5/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6313 - accuracy: 0.6519 - precision: 0.7331 - recall: 0.2994\n",
      "Epoch 5: val_accuracy did not improve from 0.66250\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 0.6313 - accuracy: 0.6519 - precision: 0.7331 - recall: 0.2994 - val_loss: 1.1705 - val_accuracy: 0.5700 - val_precision: 0.5161 - val_recall: 0.0925\n",
      "Epoch 6/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6377 - accuracy: 0.6581 - precision: 0.6942 - recall: 0.3663\n",
      "Epoch 6: val_accuracy did not improve from 0.66250\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.6377 - accuracy: 0.6581 - precision: 0.6942 - recall: 0.3663 - val_loss: 1.2270 - val_accuracy: 0.5825 - val_precision: 1.0000 - val_recall: 0.0347\n",
      "Epoch 7/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6239 - accuracy: 0.6612 - precision: 0.6941 - recall: 0.3794\n",
      "Epoch 7: val_accuracy did not improve from 0.66250\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 0.6239 - accuracy: 0.6612 - precision: 0.6941 - recall: 0.3794 - val_loss: 2.3043 - val_accuracy: 0.4425 - val_precision: 0.4346 - val_recall: 0.9595\n",
      "Epoch 8/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6278 - accuracy: 0.6488 - precision: 0.7114 - recall: 0.3081\n",
      "Epoch 8: val_accuracy did not improve from 0.66250\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.6278 - accuracy: 0.6488 - precision: 0.7114 - recall: 0.3081 - val_loss: 0.6414 - val_accuracy: 0.6175 - val_precision: 0.8571 - val_recall: 0.1387\n",
      "Epoch 9/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6215 - accuracy: 0.6594 - precision: 0.7424 - recall: 0.3183\n",
      "Epoch 9: val_accuracy did not improve from 0.66250\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.6215 - accuracy: 0.6594 - precision: 0.7424 - recall: 0.3183 - val_loss: 1.2834 - val_accuracy: 0.4425 - val_precision: 0.4352 - val_recall: 0.9711\n",
      "Epoch 10/10\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6235 - accuracy: 0.6694 - precision: 0.7345 - recall: 0.3619\n",
      "Epoch 10: val_accuracy did not improve from 0.66250\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.6235 - accuracy: 0.6694 - precision: 0.7345 - recall: 0.3619 - val_loss: 1.4108 - val_accuracy: 0.5925 - val_precision: 0.9167 - val_recall: 0.0636\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Train classification model (second phase):\n",
    "#\n",
    "history, training_time = \\\n",
    "    model_development.train_classification_model(training_phase = 2, \n",
    "    model = None, model_path = '../models/weights/VGG19_20221001_fs.hdf5', model_name = 'VGG19', version = '20221001_ss', \n",
    "    X = X_train, Y = Y_train, metric_to_monitor = 'val_accuracy', \n",
    "    no_of_epochs = 200, batch_size = 4, validation_split_ratio = 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tensorflow_latest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d1c19e37e5f6196bc516d7b965f651cc74a678b65e0e3f127f9e9132621bafc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
