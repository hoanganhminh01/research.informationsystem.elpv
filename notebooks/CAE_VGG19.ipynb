{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append(os.path.join(os.path.abspath(os.path.dirname(\"__file__\")), '..'))\n",
    "from utils import data_handling, model_development\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Configure the model training policy:\n",
    "#\n",
    "model_development.configure_training_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2624, 300, 300), 2624, 2624]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e771e163fe54ff183c300c1579b6d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='n', max=2623), Output()), _dom_classes=('widget-interactâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##\n",
    "# Load and preprocess data:\n",
    "#\n",
    "cell_images, cell_labels, cell_types = data_handling.load_data_from_file('../data/labels.csv', True)\n",
    "print([cell_images.shape, len(cell_labels), len(cell_types)])\n",
    "\n",
    "@interact(n = (0, cell_images.shape[0] - 1))\n",
    "def display_data(n = 0):\n",
    "    fig, axs = plt.subplots()\n",
    "    axs.imshow(cell_images[n], cmap = 'gray')\n",
    "    axs.set_title(f'Class: {cell_labels[n]} - Type: {cell_types[n]}')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Prepare data for model training:\n",
    "#\n",
    "mono_good = data_handling.query_data_by_labels_and_types(data = cell_images, labels = cell_labels, types = cell_types,\n",
    "    filter_by_labels = 0.0, filter_by_types = 'mono')\n",
    "poly_good = data_handling.query_data_by_labels_and_types(data = cell_images, labels = cell_labels, types = cell_types,\n",
    "    filter_by_labels = 0.0, filter_by_types = 'poly')\n",
    "X_train = np.concatenate((mono_good, poly_good), axis = 0)\n",
    "X_train = np.stack((X_train,) * 3, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.8343\n",
      "Epoch 1: val_loss improved from inf to 0.54437, saving model to ../models/weights\\CAE_VGG19_1.00.00.hdf5\n",
      "76/76 [==============================] - 102s 1s/step - loss: 0.8343 - val_loss: 0.5444\n",
      "Epoch 2/200\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.4516\n",
      "Epoch 2: val_loss improved from 0.54437 to 0.35775, saving model to ../models/weights\\CAE_VGG19_1.00.00.hdf5\n",
      "76/76 [==============================] - 81s 1s/step - loss: 0.4516 - val_loss: 0.3578\n",
      "Epoch 3/200\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3418\n",
      "Epoch 3: val_loss improved from 0.35775 to 0.31484, saving model to ../models/weights\\CAE_VGG19_1.00.00.hdf5\n",
      "76/76 [==============================] - 83s 1s/step - loss: 0.3418 - val_loss: 0.3148\n",
      "Epoch 4/200\n",
      "73/76 [===========================>..] - ETA: 2s - loss: 0.3636"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Train classification model (first phase):\n",
    "#\n",
    "optimizer = model_development.create_optimizer('nadam')\n",
    "cae_vgg19 = \\\n",
    "    model_development.cae_VGG19(input_shape = (300, 300, 3), weights = 'imagenet', freeze_convolutional_base = True, display_model_information = False)\n",
    "\n",
    "history, training_time = model_development.train_reconstruction_model(1, cae_vgg19, optimizer = optimizer,\n",
    "    training_metrics = model_development.ssim_loss, model_name = 'CAE_VGG19', version = '1.00.00',\n",
    "    X = X_train, Y = X_train, \n",
    "    metric_to_monitor = 'val_loss', no_of_epochs = 200, batch_size = 16, validation_split_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#\n",
    "#\n",
    "optimizer = model_development.create_optimizer('adam')\n",
    "history, training_time = model_development.train_reconstruction_model(2, '../models/weights/CAE_VGG19_1.00.00_fs.hdf5',\n",
    "    optimizer = optimizer, training_metrics = model_development.ssim_loss, \n",
    "    model_name = 'CAE_VGG19', version = '1.00.00_ss',\n",
    "    X = X_train, Y = X_train, \n",
    "    metric_to_monitor = 'val_loss', no_of_epochs = 200, batch_size = 16, validation_split_ratio = 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tensorflow_latest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d1c19e37e5f6196bc516d7b965f651cc74a678b65e0e3f127f9e9132621bafc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
