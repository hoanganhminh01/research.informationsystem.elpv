{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.abspath(os.path.dirname(\"__file__\")), '..'))\n",
    "from utils import data_handling, model_development\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Configure the model training policy:\n",
    "#\n",
    "model_development.configure_training_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2624, 300, 300), 2624, 2624]\n",
      "[(2624, 300, 300, 3), 2624, 2624]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eaf996597ae44e8837c2c7637b32028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='n', max=2623), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a834952a764641d2b3d1ec41395425df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='n', max=2623), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##\n",
    "# Load and preprocess data:\n",
    "#\n",
    "cell_images, cell_labels, cell_types = data_handling.load_data_from_file('../data/labels.csv', True)\n",
    "X, Y, Z = data_handling.preprocess_data(cell_images, cell_labels, cell_types)\n",
    "\n",
    "print([cell_images.shape, len(cell_labels), len(cell_types)])\n",
    "print([X.shape, len(Y), len(Z)])\n",
    "\n",
    "@interact(n = (0, cell_images.shape[0] - 1))\n",
    "def display_data(n = 0):\n",
    "    fig, axs = plt.subplots()\n",
    "    axs.imshow(cell_images[n], cmap = 'gray')\n",
    "    axs.set_title(f'Class: {cell_labels[n]} - Type: {cell_types[n]}')\n",
    "    return None\n",
    "\n",
    "@interact(n = (0, X.shape[0] - 1))\n",
    "def display_data(n = 0):\n",
    "    fig, axs = plt.subplots()\n",
    "    axs.imshow(X[n], cmap = 'gray')\n",
    "    axs.set_title(f'Class: {Y[n]} - Type: {Z[n]}')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Prepare data for model training:\n",
    "#\n",
    "train_test_split = int(0.85 * X.shape[0])\n",
    "X_train, Y_train, Z_train = X[: train_test_split], Y[: train_test_split], Z[: train_test_split]\n",
    "X_test, Y_test, Z_test = X[train_test_split : ], Y[train_test_split : ], Z[train_test_split : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "446/446 [==============================] - ETA: 0s - loss: 0.6880 - accuracy: 0.5757 - precision: 0.4864 - recall: 0.3118\n",
      "Epoch 1: val_accuracy improved from -inf to 0.63453, saving model to ../models/weights\\VGG19_20221003_fs.hdf5\n",
      "446/446 [==============================] - 21s 42ms/step - loss: 0.6880 - accuracy: 0.5757 - precision: 0.4864 - recall: 0.3118 - val_loss: 0.6741 - val_accuracy: 0.6345 - val_precision: 0.6410 - val_recall: 0.4831\n",
      "Epoch 2/10\n",
      "445/446 [============================>.] - ETA: 0s - loss: 0.6757 - accuracy: 0.6000 - precision: 0.5320 - recall: 0.3575\n",
      "Epoch 2: val_accuracy did not improve from 0.63453\n",
      "446/446 [==============================] - 18s 41ms/step - loss: 0.6749 - accuracy: 0.6009 - precision: 0.5320 - recall: 0.3575 - val_loss: 0.6971 - val_accuracy: 0.5359 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/10\n",
      "445/446 [============================>.] - ETA: 0s - loss: 0.6518 - accuracy: 0.6337 - precision: 0.5925 - recall: 0.3846\n",
      "Epoch 3: val_accuracy did not improve from 0.63453\n",
      "446/446 [==============================] - 18s 41ms/step - loss: 0.6537 - accuracy: 0.6328 - precision: 0.5925 - recall: 0.3831 - val_loss: 0.6849 - val_accuracy: 0.5516 - val_precision: 0.8182 - val_recall: 0.0435\n",
      "Epoch 4/10\n",
      "445/446 [============================>.] - ETA: 0s - loss: 0.6478 - accuracy: 0.6326 - precision: 0.5865 - recall: 0.4099\n",
      "Epoch 4: val_accuracy did not improve from 0.63453\n",
      "446/446 [==============================] - 18s 41ms/step - loss: 0.6479 - accuracy: 0.6323 - precision: 0.5843 - recall: 0.4099 - val_loss: 0.6834 - val_accuracy: 0.5291 - val_precision: 0.4957 - val_recall: 0.8406\n",
      "Epoch 5/10\n",
      "445/446 [============================>.] - ETA: 0s - loss: 0.6443 - accuracy: 0.6427 - precision: 0.6059 - recall: 0.4153\n",
      "Epoch 5: val_accuracy did not improve from 0.63453\n",
      "446/446 [==============================] - 18s 41ms/step - loss: 0.6437 - accuracy: 0.6435 - precision: 0.6059 - recall: 0.4153 - val_loss: 0.6983 - val_accuracy: 0.5516 - val_precision: 0.8182 - val_recall: 0.0435\n",
      "Epoch 6/10\n",
      "445/446 [============================>.] - ETA: 0s - loss: 0.6306 - accuracy: 0.6326 - precision: 0.5844 - recall: 0.4145\n",
      "Epoch 6: val_accuracy did not improve from 0.63453\n",
      "446/446 [==============================] - 18s 41ms/step - loss: 0.6305 - accuracy: 0.6328 - precision: 0.5844 - recall: 0.4140 - val_loss: 0.7013 - val_accuracy: 0.5561 - val_precision: 0.8462 - val_recall: 0.0531\n",
      "Epoch 7/10\n",
      "445/446 [============================>.] - ETA: 0s - loss: 0.6284 - accuracy: 0.6522 - precision: 0.6152 - recall: 0.4455\n",
      "Epoch 7: val_accuracy did not improve from 0.63453\n",
      "446/446 [==============================] - 18s 41ms/step - loss: 0.6277 - accuracy: 0.6530 - precision: 0.6160 - recall: 0.4462 - val_loss: 0.6614 - val_accuracy: 0.6345 - val_precision: 0.6019 - val_recall: 0.6280\n",
      "Epoch 8/10\n",
      "445/446 [============================>.] - ETA: 0s - loss: 0.6156 - accuracy: 0.6815 - precision: 0.6660 - recall: 0.4772\n",
      "Epoch 8: val_accuracy did not improve from 0.63453\n",
      "446/446 [==============================] - 18s 40ms/step - loss: 0.6152 - accuracy: 0.6822 - precision: 0.6660 - recall: 0.4772 - val_loss: 0.6721 - val_accuracy: 0.5874 - val_precision: 0.7091 - val_recall: 0.1884\n",
      "Epoch 9/10\n",
      "445/446 [============================>.] - ETA: 0s - loss: 0.6089 - accuracy: 0.6949 - precision: 0.6932 - recall: 0.4811\n",
      "Epoch 9: val_accuracy did not improve from 0.63453\n",
      "446/446 [==============================] - 18s 41ms/step - loss: 0.6092 - accuracy: 0.6945 - precision: 0.6925 - recall: 0.4812 - val_loss: 0.7011 - val_accuracy: 0.5067 - val_precision: 0.4833 - val_recall: 0.9082\n",
      "Epoch 10/10\n",
      "445/446 [============================>.] - ETA: 0s - loss: 0.6129 - accuracy: 0.6601 - precision: 0.6217 - recall: 0.4772\n",
      "Epoch 10: val_accuracy improved from 0.63453 to 0.65022, saving model to ../models/weights\\VGG19_20221003_fs.hdf5\n",
      "446/446 [==============================] - 18s 41ms/step - loss: 0.6124 - accuracy: 0.6609 - precision: 0.6217 - recall: 0.4772 - val_loss: 0.6531 - val_accuracy: 0.6502 - val_precision: 0.6244 - val_recall: 0.6184\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Train classification model (first phase):\n",
    "#\n",
    "optimizer = model_development.create_optimizer('adam')\n",
    "vgg19 = \\\n",
    "    model_development.vgg19(input_shape = (300, 300, 3), weights = 'imagenet', freeze_convolutional_base = True, display_model_information = False)\n",
    "\n",
    "history, training_time = \\\n",
    "    model_development.train_classification_model(training_phase = 1, model = vgg19, \n",
    "    optimizer = optimizer, training_metrics = ['accuracy', 'Precision', 'Recall'],\n",
    "    model_name = 'VGG19', version = '20221003_fs', \n",
    "    X = X_train, Y = Y_train, metric_to_monitor = 'val_accuracy', \n",
    "    no_of_epochs = 5, batch_size = 4, validation_split_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "446/446 [==============================] - ETA: 0s - loss: 0.6253 - accuracy: 0.6715 - precision: 0.6804 - recall: 0.4005\n",
      "Epoch 1: val_accuracy improved from -inf to 0.69058, saving model to ../models/weights\\VGG19_20221003_ss.hdf5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create dataset (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m##\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Train classification model (second phase):\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      4\u001b[0m history, training_time \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m----> 5\u001b[0m     model_development\u001b[38;5;241m.\u001b[39mtrain_classification_model(training_phase \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \n\u001b[0;32m      6\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/weights/VGG19_20221003_fs.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      7\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optimizer, training_metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      8\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVGG19\u001b[39m\u001b[38;5;124m'\u001b[39m, version \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20221003_ss\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      9\u001b[0m     X \u001b[38;5;241m=\u001b[39m X_train, Y \u001b[38;5;241m=\u001b[39m Y_train, metric_to_monitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     10\u001b[0m     no_of_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m, validation_split_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\vohuynhq\\OneDrive - Intel Corporation\\Desktop\\Github Desktop\\research.informationsystem.elpv\\notebooks\\..\\utils\\model_development.py:115\u001b[0m, in \u001b[0;36mtrain_classification_model\u001b[1;34m(training_phase, model, optimizer, training_metrics, model_name, version, X, Y, metric_to_monitor, no_of_epochs, batch_size, validation_split_ratio)\u001b[0m\n\u001b[0;32m    112\u001b[0m checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(weight_path, monitor \u001b[39m=\u001b[39m metric_to_monitor, \n\u001b[0;32m    113\u001b[0m     verbose \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, save_best_only \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    114\u001b[0m callbacks_list \u001b[39m=\u001b[39m [checkpoint]\n\u001b[1;32m--> 115\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X, Y, validation_split \u001b[39m=\u001b[39;49m validation_split_ratio, epochs \u001b[39m=\u001b[39;49m no_of_epochs, \n\u001b[0;32m    116\u001b[0m     batch_size \u001b[39m=\u001b[39;49m batch_size, callbacks \u001b[39m=\u001b[39;49m callbacks_list, verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, shuffle \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    117\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../models/history/\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mversion\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, history\u001b[39m.\u001b[39mhistory)\n\u001b[0;32m    118\u001b[0m \u001b[39m###\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tensorflow_latest\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tensorflow_latest\\lib\\site-packages\\h5py\\_hl\\group.py:149\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[1;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[0;32m    146\u001b[0m         parent_path, name \u001b[39m=\u001b[39m name\u001b[39m.\u001b[39mrsplit(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    147\u001b[0m         group \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequire_group(parent_path)\n\u001b[1;32m--> 149\u001b[0m dsid \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmake_new_dset(group, shape, dtype, data, name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    150\u001b[0m dset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mDataset(dsid)\n\u001b[0;32m    151\u001b[0m \u001b[39mreturn\u001b[39;00m dset\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tensorflow_latest\\lib\\site-packages\\h5py\\_hl\\dataset.py:142\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[1;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     sid \u001b[39m=\u001b[39m h5s\u001b[39m.\u001b[39mcreate_simple(shape, maxshape)\n\u001b[1;32m--> 142\u001b[0m dset_id \u001b[39m=\u001b[39m h5d\u001b[39m.\u001b[39;49mcreate(parent\u001b[39m.\u001b[39;49mid, name, tid, sid, dcpl\u001b[39m=\u001b[39;49mdcpl)\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m (data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Empty)):\n\u001b[0;32m    145\u001b[0m     dset_id\u001b[39m.\u001b[39mwrite(h5s\u001b[39m.\u001b[39mALL, h5s\u001b[39m.\u001b[39mALL, data)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5d.pyx:87\u001b[0m, in \u001b[0;36mh5py.h5d.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to create dataset (name already exists)"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Train classification model (second phase):\n",
    "#\n",
    "history, training_time = \\\n",
    "    model_development.train_classification_model(training_phase = 2, \n",
    "    model = '../models/weights/VGG19_20221003_fs.hdf5', \n",
    "    optimizer = optimizer, training_metrics = ['accuracy', 'Precision', 'Recall'],\n",
    "    model_name = 'VGG19', version = '20221003_ss', \n",
    "    X = X_train, Y = Y_train, metric_to_monitor = 'val_accuracy', \n",
    "    no_of_epochs = 5, batch_size = 4, validation_split_ratio = 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tensorflow_latest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d1c19e37e5f6196bc516d7b965f651cc74a678b65e0e3f127f9e9132621bafc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
