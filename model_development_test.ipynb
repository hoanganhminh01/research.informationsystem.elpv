{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Train a Digit Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Import necessary libraries\n",
    "Here is the sample code of how to import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "\n",
    "from ipywidgets import interact\n",
    "from keras import layers, Model, optimizers\n",
    "from keras.applications import VGG19\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:  Setup GPU’s memory policies and tensor’s behavior\n",
    "\n",
    "Here is the sample code of how to setup GPU’s memory policies and tensor’s behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices  =  tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "            tf.experimental.numpy.experimental_enable_numpy_behavior(prefer_float32 = True)\n",
    "    except RuntimeError as error:\n",
    "        print(error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Loading and Preprocessing\n",
    "\n",
    "Here is the sample code of how to load, preprocess, and interact with the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(60000, 64, 64, 3), (60000, 10)]\n",
      "[(10000, 64, 64, 3), (60000, 10)]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_mnist(x: object, y: object, x_new_shape: tuple) ->tuple[object, object]:\n",
    "    \"\"\"\n",
    "    @author: Vo, Huynh Quang Nguyen\n",
    "\n",
    "    Preprocess the MNIST dataset.\n",
    "\n",
    "    This function preprocess_mnist preprocesses the MNIST dataset by:\n",
    "    1. Upscaling the dimensions of the input images (from)\n",
    "    \"\"\"\n",
    "    x = x.reshape(x.shape[0], 28, 28, 1).astype('float32')\n",
    "    x = tf.image.resize(x, x_new_shape)\n",
    "    x = np.stack((x[:,:,:,0],) * 3, axis = -1) \n",
    "    x = x.astype('float32') / 255.0\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    return x, y \n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, y_train = preprocess_mnist(x_train, y_train, (64,64))\n",
    "x_test, y_test= preprocess_mnist(x_test, y_test, (64,64))\n",
    "\n",
    "print([x_train.shape, y_train.shape])\n",
    "print([x_test.shape, y_train.shape])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the model\n",
    "Here is the sample code of how to define a model using Keras functional API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " globavgpool (GlobalAverageP  (None, 512)              0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 4096)              2101248   \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,166,602\n",
      "Trainable params: 22,166,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def vgg19(input_shape: tuple) -> object:\n",
    "    \"\"\"\n",
    "    @author: Vo, Huynh Quang Nguyen\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape = input_shape, name = 'inputs')\n",
    "    vggmodel = VGG19(include_top = False, input_tensor = inputs, weights = 'imagenet')\n",
    "    vggmodel.trainable = True\n",
    "    x = vggmodel.output\n",
    "    x = layers.GlobalAveragePooling2D(name = 'globavgpool')(x)\n",
    "    x = layers.Dense(4096, activation = 'relu', name = 'dense1')(x)\n",
    "    outputs = layers.Dense(10, activation = 'softmax', name = 'outputs')(x)\n",
    "    model = Model(inputs = inputs, outputs = outputs, name = 'VGG19')\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = optimizers.Adam(learning_rate = 0.0001), \n",
    "                  metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "vgg19 = vgg19((64,64,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the model\n",
    "\n",
    "Here is the sample code of how to train the model using `ModelCheckpoint` from Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9703"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Failed to format this callback filepath: \"weights/{model_name:5s}_{epoch:02d}_{val_accuracy:.2f}.hdf5\". Reason: \\'model_name\\''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\Documents\\GitHub\\research.informationsystem.elpv\\model_development_test.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/GitHub/research.informationsystem.elpv/model_development_test.ipynb#X22sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     training_time \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(end_time \u001b[39m-\u001b[39m start_time, \u001b[39m4\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/GitHub/research.informationsystem.elpv/model_development_test.ipynb#X22sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m history, training_time\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/GitHub/research.informationsystem.elpv/model_development_test.ipynb#X22sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m train_classification_model(vgg19, \u001b[39m'\u001b[39;49m\u001b[39mVGG19\u001b[39;49m\u001b[39m'\u001b[39;49m, x_train, y_train, \u001b[39m'\u001b[39;49m\u001b[39mval_accuracy\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m10\u001b[39;49m, \u001b[39m32\u001b[39;49m, \u001b[39m0.33\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Admin\\Documents\\GitHub\\research.informationsystem.elpv\\model_development_test.ipynb Cell 11\u001b[0m in \u001b[0;36mtrain_classification_model\u001b[1;34m(model, model_name, X, Y, metric_to_monitor, no_of_epochs, batch_size, validation_split_ratio)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/GitHub/research.informationsystem.elpv/model_development_test.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(weight_path, monitor \u001b[39m=\u001b[39m metric_to_monitor, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/GitHub/research.informationsystem.elpv/model_development_test.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     verbose \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, save_best_only \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/GitHub/research.informationsystem.elpv/model_development_test.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m callbacks_list \u001b[39m=\u001b[39m [checkpoint]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/GitHub/research.informationsystem.elpv/model_development_test.ipynb#X22sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X, Y, validation_split \u001b[39m=\u001b[39;49m validation_split_ratio, epochs \u001b[39m=\u001b[39;49m no_of_epochs, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/GitHub/research.informationsystem.elpv/model_development_test.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     batch_size \u001b[39m=\u001b[39;49m batch_size, callbacks \u001b[39m=\u001b[39;49m callbacks_list, verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/GitHub/research.informationsystem.elpv/model_development_test.ipynb#X22sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m_history.npy\u001b[39m\u001b[39m'\u001b[39m, history\u001b[39m.\u001b[39mhistory)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/GitHub/research.informationsystem.elpv/model_development_test.ipynb#X22sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m###\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tensorflow_latest\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tensorflow_latest\\lib\\site-packages\\keras\\callbacks.py:1487\u001b[0m, in \u001b[0;36mModelCheckpoint._get_file_path\u001b[1;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m     file_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepath\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1485\u001b[0m         epoch\u001b[39m=\u001b[39mepoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, batch\u001b[39m=\u001b[39mbatch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mlogs)\n\u001b[0;32m   1486\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1487\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[0;32m   1488\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFailed to format this callback filepath: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1489\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mReason: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_write_filepath \u001b[39m=\u001b[39m distributed_file_utils\u001b[39m.\u001b[39mwrite_filepath(\n\u001b[0;32m   1491\u001b[0m     file_path, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mdistribute_strategy)\n\u001b[0;32m   1492\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_write_filepath\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Failed to format this callback filepath: \"weights/{model_name:5s}_{epoch:02d}_{val_accuracy:.2f}.hdf5\". Reason: \\'model_name\\''"
     ]
    }
   ],
   "source": [
    "def train_classification_model(model: object, model_name: str, X: object, Y: object, \n",
    "    metric_to_monitor: str, no_of_epochs: int, batch_size: int, validation_split_ratio: float) -> tuple[object, float]:\n",
    "    \"\"\"\n",
    "    @author: Vo, Huynh Quang Nguyen\n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    ###\n",
    "    weight_path = 'weights/VGG19_{epoch:02d}_{val_accuracy:.2f}.hdf5'\n",
    "    checkpoint = ModelCheckpoint(weight_path, monitor = metric_to_monitor, \n",
    "        verbose = 1, save_best_only = True, mode = 'max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    history = model.fit(X, Y, validation_split = validation_split_ratio, epochs = no_of_epochs, \n",
    "        batch_size = batch_size, callbacks = callbacks_list, verbose = 1)\n",
    "    np.save(f'{model_name}_history.npy', history.history)\n",
    "    ###\n",
    "    end_time = time.time()\n",
    "\n",
    "    training_time = round(end_time - start_time, 4)\n",
    "    return history, training_time\n",
    "\n",
    "train_classification_model(vgg19, 'VGG19', x_train, y_train, 'val_accuracy', 10, 32, 0.33)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tensorflow_latest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d1c19e37e5f6196bc516d7b965f651cc74a678b65e0e3f127f9e9132621bafc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
